"""
AI Agent –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ –∫–æ–¥–∞
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Ollama –∏ –ø—Ä—è–º—É—é —Ä–∞–±–æ—Ç—É —Å transformers
"""

import os
import json
import yaml
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Generator
import requests
from rich.console import Console
from rich.markdown import Markdown
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ò–º–ø–æ—Ä—Ç MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
try:
    from mcp_tools import MCPToolManager, format_tools_for_prompt
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False
    console = Console()
    console.print("[yellow]MCP tools not available[/yellow]")

if not MCP_AVAILABLE:
    console = Console()
else:
    console = Console()


class CodeAgent:
    """AI –∞–≥–µ–Ω—Ç –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ –∫–æ–¥–∞"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞"""
        self.config = self._load_config(config_path)
        self.provider = self.config['model']['provider']
        self.model_name = self.config['model']['model_name']
        self.history: List[Dict] = []
        self.history_path = Path(self.config['agent']['history_path'])
        self.history_path.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        self.use_mcp = self.config.get('mcp', {}).get('enabled', True) and MCP_AVAILABLE
        if self.use_mcp:
            self.mcp_tools = MCPToolManager()
            console.print(f"[green]MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(self.mcp_tools.list_tools())} –¥–æ—Å—Ç—É–ø–Ω–æ[/green]")
        else:
            self.mcp_tools = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        if self.provider == "ollama":
            self._init_ollama()
        elif self.provider == "lmstudio":
            self._init_lmstudio()
        elif self.provider == "local_transformers":
            self._init_transformers()
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.provider}")
    
    def _load_config(self, config_path: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        if not os.path.exists(config_path):
            console.print(f"[yellow]–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é[/yellow]")
            return self._default_config()
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _default_config(self) -> Dict:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'model': {
                'provider': 'ollama',
                'model_name': 'deepseek-coder:6.7b'
            },
            'agent': {
                'system_prompt': '–¢—ã –æ–ø—ã—Ç–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.',
                'history_path': './history'
            }
        }
    
    def _init_ollama(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama"""
        self.ollama_url = self.config.get('ollama', {}).get('base_url', 'http://localhost:11434')
        self.timeout = self.config.get('ollama', {}).get('timeout', 300)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m['name'] for m in models]
                console.print(f"[green]Ollama –ø–æ–¥–∫–ª—é—á–µ–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(model_names)}[/green]")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω–æ–π –º–æ–¥–µ–ª–∏
                if self.model_name not in model_names:
                    console.print(f"[yellow]–ú–æ–¥–µ–ª—å {self.model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: ollama pull {self.model_name}[/yellow]")
            else:
                console.print(f"[red]Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω.[/red]")
        except Exception as e:
            console.print(f"[red]–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}[/red]")
            console.print(f"[yellow]–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama: https://ollama.ai[/yellow]")
    
    def _init_lmstudio(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LM Studio"""
        self.lmstudio_url = self.config.get('lmstudio', {}).get('base_url', 'http://localhost:1234')
        self.timeout = self.config.get('lmstudio', {}).get('timeout', 300)
        self.available_models = []  # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        
        # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏
        for attempt in range(3):
            try:
                timeout = 5 + (attempt * 5)  # 5, 10, 15 —Å–µ–∫—É–Ω–¥
                response = requests.get(f"{self.lmstudio_url}/v1/models", timeout=timeout)
                
                if response.status_code == 200:
                    data = response.json()
                    models = data.get('data', [])
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –º–æ–¥–µ–ª–µ–π
                    model_ids = []
                    for m in models:
                        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è
                        model_id = m.get('id') or m.get('model') or m.get('name') or ''
                        if model_id:
                            model_ids.append(model_id)
                    
                    self.available_models = model_ids
                    
                    if model_ids:
                        console.print(f"[green]LM Studio –ø–æ–¥–∫–ª—é—á–µ–Ω. –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(model_ids)}[/green]")
                        for i, mid in enumerate(model_ids, 1):
                            console.print(f"  {i}. {mid}")
                        
                        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é
                        if not self.model_name or self.model_name not in model_ids:
                            if model_ids:
                                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ—Ö–æ–∂—É—é –º–æ–¥–µ–ª—å (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
                                found_model = None
                                if self.model_name:
                                    # –ò—â–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ—Ö–æ–∂–∏–º –∏–º–µ–Ω–µ–º
                                    for mid in model_ids:
                                        if self.model_name.lower() in mid.lower() or mid.lower() in self.model_name.lower():
                                            found_model = mid
                                            break
                                
                                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ—Ö–æ–∂—É—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é
                                self.model_name = found_model or model_ids[0]
                                if found_model:
                                    console.print(f"[yellow]–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Ö–æ–∂–∞—è –º–æ–¥–µ–ª—å: {self.model_name}[/yellow]")
                                else:
                                    console.print(f"[yellow]–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤–∞—è –¥–æ—Å—Ç—É–ø–Ω–∞—è –º–æ–¥–µ–ª—å: {self.model_name}[/yellow]")
                                console.print(f"[cyan]–î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(model_ids)}. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—É—é –∏–∑ –Ω–∏—Ö.[/cyan]")
                        else:
                            console.print(f"[green]–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–∫–∞–∑–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {self.model_name}[/green]")
                            console.print(f"[cyan]–î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(model_ids)}. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—É—é –∏–∑ –Ω–∏—Ö.[/cyan]")
                        return
                    else:
                        console.print(f"[yellow]–ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –æ—Ç–≤–µ—Ç–µ API[/yellow]")
                        console.print(f"[yellow]–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç: {data}[/yellow]")
                
                elif response.status_code == 502:
                    if attempt < 2:
                        import time
                        wait_time = (attempt + 1) * 3
                        console.print(f"[yellow]–°–µ—Ä–≤–µ—Ä –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 502, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3, –∂–¥–µ–º {wait_time}—Å...[/yellow]")
                        time.sleep(wait_time)
                        continue
                    else:
                        console.print(f"[yellow]LM Studio —Å–µ—Ä–≤–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç, –Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 502[/yellow]")
                        console.print(f"[yellow]–ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤–∞. –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {self.model_name}[/yellow]")
                        return
                else:
                    console.print(f"[yellow]LM Studio –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {response.status_code}[/yellow]")
                    if attempt < 2:
                        continue
                    
            except requests.exceptions.Timeout:
                if attempt < 2:
                    console.print(f"[yellow]–¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3...[/yellow]")
                    continue
                else:
                    console.print(f"[yellow]–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ LM Studio (—Ç–∞–π–º–∞—É—Ç)[/yellow]")
            except requests.exceptions.ConnectionError:
                if attempt < 2:
                    import time
                    time.sleep(2)
                    continue
                else:
                    console.print(f"[red]–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ LM Studio[/red]")
                    console.print(f"[yellow]–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ LM Studio –∑–∞–ø—É—â–µ–Ω –∏ Local Server –≤–∫–ª—é—á–µ–Ω[/yellow]")
            except Exception as e:
                console.print(f"[red]–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LM Studio: {e}[/red]")
                if attempt < 2:
                    import time
                    time.sleep(2)
                    continue
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏, –Ω–æ –º–æ–¥–µ–ª—å —É–∫–∞–∑–∞–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–µ
        if self.model_name:
            console.print(f"[yellow]–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {self.model_name}[/yellow]")
            console.print(f"[yellow]–ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –µ—ë –Ω–∞–ª–∏—á–∏–µ –≤ LM Studio[/yellow]")
            console.print(f"[cyan]–ù–∞—à–µ –ü–û –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª—é–±—É—é –º–æ–¥–µ–ª—å –∏–∑ LM Studio - –ø—Ä–æ—Å—Ç–æ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –µ—ë –≤ LM Studio[/cyan]")
    
    def _init_transformers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è transformers (–¥–ª—è –ø—Ä—è–º–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π)"""
        try:
            import torch
            from transformers import AutoTokenizer, AutoModelForCausalLM
            
            model_path = self.config['model'].get('model_path') or self.model_name
            device = self.config['model'].get('device', 'cuda')
            
            console.print(f"[cyan]–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_path}...[/cyan]")
            
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForCausalLM.from_pretrained(
                model_path,
                torch_dtype=torch.float16 if device == 'cuda' else torch.float32,
                device_map='auto' if device == 'cuda' else None,
            )
            
            if device == 'cpu':
                self.model = self.model.to(device)
            
            console.print(f"[green]–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞[/green]")
        except Exception as e:
            console.print(f"[red]–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}[/red]")
            raise
    
    def _build_messages(self, user_prompt: str) -> List[Dict]:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏"""
        messages = []
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = self.config['agent'].get('system_prompt', '')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if self.use_mcp and self.mcp_tools:
            tools_info = format_tools_for_prompt(self.mcp_tools)
            if tools_info:
                system_prompt += "\n\n" + tools_info
        
        if system_prompt:
            messages.append({
                'role': 'system',
                'content': system_prompt
            })
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        for msg in self.history[-10:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
            messages.append(msg)
        
        # –¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        messages.append({
            'role': 'user',
            'content': user_prompt
        })
        
        return messages
    
    def _call_ollama(self, messages: List[Dict], stream: bool = False) -> Generator[str, None, None]:
        """–í—ã–∑–æ–≤ Ollama API"""
        url = f"{self.ollama_url}/api/chat"
        
        generation_config = self.config['model']['generation']
        
        payload = {
            'model': self.model_name,
            'messages': messages,
            'stream': stream,
            'options': {
                'temperature': generation_config.get('temperature', 0.2),
                'top_p': generation_config.get('top_p', 0.95),
                'top_k': generation_config.get('top_k', 40),
                'num_predict': generation_config.get('max_tokens', 4096),
            }
        }
        
        try:
            response = requests.post(
                url,
                json=payload,
                stream=stream,
                timeout=self.timeout
            )
            response.raise_for_status()
            
            if stream:
                for line in response.iter_lines():
                    if line:
                        data = json.loads(line)
                        if 'message' in data and 'content' in data['message']:
                            yield data['message']['content']
                        if data.get('done', False):
                            break
            else:
                result = response.json()
                yield result['message']['content']
                
        except requests.exceptions.RequestException as e:
            console.print(f"[red]–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama: {e}[/red]")
            yield f"–û—à–∏–±–∫–∞: {e}"
    
    def _call_lmstudio(self, messages: List[Dict], stream: bool = False) -> Generator[str, None, None]:
        """–í—ã–∑–æ–≤ LM Studio API (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)"""
        url = f"{self.lmstudio_url}/v1/chat/completions"
        
        generation_config = self.config['model']['generation']
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
        formatted_messages = []
        for msg in messages:
            if msg['role'] == 'system':
                # LM Studio –º–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å system role –Ω–∞–ø—Ä—è–º—É—é, –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ user
                formatted_messages.append({
                    'role': 'user',
                    'content': f"System: {msg['content']}"
                })
            else:
                formatted_messages.append({
                    'role': msg['role'],
                    'content': msg['content']
                })
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π payload –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        payload = {
            'model': self.model_name,
            'messages': formatted_messages,
            'stream': stream,
            'temperature': generation_config.get('temperature', 0.7),
            'max_tokens': min(generation_config.get('max_tokens', 4096), 2000),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω—ã
        if generation_config.get('top_p'):
            payload['top_p'] = generation_config.get('top_p')
        
        try:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π
            timeout = max(self.timeout, 180)  # –ú–∏–Ω–∏–º—É–º 3 –º–∏–Ω—É—Ç—ã
            
            # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Å –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏ –∏ —É–≤–µ–ª–∏—á–∏–≤–∞—é—â–∏–º–∏—Å—è —Ç–∞–π–º–∞—É—Ç–∞–º–∏
            max_retries = 5
            response = None
            
            for attempt in range(max_retries):
                try:
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç —Å –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    current_timeout = timeout + (attempt * 30)  # 180, 210, 240, 270, 300
                    
                    response = requests.post(
                        url,
                        json=payload,
                        stream=stream,
                        timeout=current_timeout,
                        headers={
                            'Content-Type': 'application/json',
                            'Accept': 'application/json'
                        }
                    )
                    
                    # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ 200 - –æ—Ç–ª–∏—á–Ω–æ
                    if response.status_code == 200:
                        break
                    
                    # –ï—Å–ª–∏ 502 –∏ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∂–¥–µ–º –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                    if response.status_code == 502 and attempt < max_retries - 1:
                        import time
                        wait_time = (attempt + 1) * 10  # 10, 20, 30, 40 —Å–µ–∫—É–Ω–¥
                        console.print(f"[yellow]–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}, –∂–¥–µ–º {wait_time}—Å)...[/yellow]")
                        time.sleep(wait_time)
                        continue
                    
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ - –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(5)
                        continue
                    
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –≤—ã—Ö–æ–¥–∏–º
                    response.raise_for_status()
                    break
                    
                except requests.exceptions.HTTPError as e:
                    if e.response.status_code == 502 and attempt < max_retries - 1:
                        import time
                        wait_time = (attempt + 1) * 10
                        console.print(f"[yellow]–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {wait_time}—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...[/yellow]")
                        time.sleep(wait_time)
                        continue
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(5)
                        continue
                    raise
                except requests.exceptions.Timeout:
                    if attempt < max_retries - 1:
                        import time
                        wait_time = (attempt + 1) * 5
                        console.print(f"[yellow]–¢–∞–π–º–∞—É—Ç, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {wait_time}—Å...[/yellow]")
                        time.sleep(wait_time)
                        continue
                    raise
            
            if not response:
                raise requests.exceptions.RequestException("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
            
            response.raise_for_status()
            
            if stream:
                for line in response.iter_lines():
                    if line:
                        line_text = line.decode('utf-8')
                        if line_text.startswith('data: '):
                            data_str = line_text[6:]
                            if data_str.strip() == '[DONE]':
                                break
                            try:
                                data = json.loads(data_str)
                                if 'choices' in data and len(data['choices']) > 0:
                                    delta = data['choices'][0].get('delta', {})
                                    content = delta.get('content', '')
                                    if content:
                                        yield content
                            except json.JSONDecodeError:
                                continue
            else:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    yield result['choices'][0]['message']['content']
                else:
                    yield "–û—à–∏–±–∫–∞: –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞"
                
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 502:
                error_msg = (
                    "–û—à–∏–±–∫–∞ 502: –°–µ—Ä–≤–µ—Ä LM Studio –Ω–µ –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å.\n\n"
                    "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                    "1. –ú–æ–¥–µ–ª—å –µ—â–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è - –ø–æ–¥–æ–∂–¥–∏—Ç–µ 30-60 —Å–µ–∫—É–Ω–¥\n"
                    "2. –°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ\n"
                    "3. –ú–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è –¥–ª—è —Å–∏—Å—Ç–µ–º—ã\n\n"
                    "–†–µ—à–µ–Ω–∏–µ:\n"
                    "- –í LM Studio —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Ç–∞—Ç—É—Å 'READY'\n"
                    "- –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Local Server –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö LM Studio\n"
                    "- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å"
                )
                console.print(f"[red]{error_msg}[/red]")
                yield error_msg
            else:
                console.print(f"[red]–û—à–∏–±–∫–∞ HTTP {e.response.status_code}: {e}[/red]")
                yield f"–û—à–∏–±–∫–∞ HTTP {e.response.status_code}: {e}"
        except requests.exceptions.RequestException as e:
            console.print(f"[red]–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LM Studio: {e}[/red]")
            yield f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}\n\n–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:\n1. LM Studio –∑–∞–ø—É—â–µ–Ω\n2. Local Server –≤–∫–ª—é—á–µ–Ω\n3. –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
    
    def _call_transformers(self, messages: List[Dict], stream: bool = False) -> Generator[str, None, None]:
        """–í—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ transformers"""
        import torch
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç
        prompt = self._format_messages(messages)
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        inputs = self.tokenizer(prompt, return_tensors="pt")
        if self.config['model'].get('device') == 'cuda':
            inputs = {k: v.cuda() for k, v in inputs.items()}
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        generation_config = self.config['model']['generation']
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=generation_config.get('max_tokens', 4096),
                temperature=generation_config.get('temperature', 0.2),
                top_p=generation_config.get('top_p', 0.95),
                top_k=generation_config.get('top_k', 40),
                repetition_penalty=generation_config.get('repetition_penalty', 1.1),
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        generated_text = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
        
        if stream:
            # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥
            words = generated_text.split()
            for word in words:
                yield word + " "
        else:
            yield generated_text
    
    def _format_messages(self, messages: List[Dict]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ø—Ä–æ–º–ø—Ç"""
        formatted = []
        for msg in messages:
            role = msg['role']
            content = msg['content']
            if role == 'system':
                formatted.append(f"System: {content}\n")
            elif role == 'user':
                formatted.append(f"User: {content}\n")
            elif role == 'assistant':
                formatted.append(f"Assistant: {content}\n")
        
        formatted.append("Assistant: ")
        return "\n".join(formatted)
    
    def _parse_tool_calls(self, text: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        tool_calls = []
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω TOOL_CALL: tool_name {json_params}
        pattern = r'TOOL_CALL:\s*(\w+)\s*(\{.*?\})'
        matches = re.finditer(pattern, text, re.DOTALL)
        
        for match in matches:
            tool_name = match.group(1)
            params_str = match.group(2)
            try:
                params = json.loads(params_str)
                tool_calls.append({
                    'tool': tool_name,
                    'params': params
                })
            except json.JSONDecodeError:
                console.print(f"[yellow]–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {tool_name}[/yellow]")
        
        return tool_calls
    
    def _execute_tool_calls(self, tool_calls: List[Dict]) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        results = []
        
        for call in tool_calls:
            tool_name = call['tool']
            params = call['params']
            
            if not self.use_mcp or not self.mcp_tools:
                results.append(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {tool_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (MCP –æ—Ç–∫–ª—é—á–µ–Ω)")
                continue
            
            console.print(f"[cyan]–í—ã–ø–æ–ª–Ω—è—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool_name}[/cyan]")
            result = self.mcp_tools.execute_tool(tool_name, **params)
            
            if 'error' in result:
                results.append(f"–û—à–∏–±–∫–∞ {tool_name}: {result['error']}")
            else:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
                result_str = json.dumps(result, ensure_ascii=False, indent=2)
                results.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {tool_name}:\n{result_str}")
        
        return "\n\n".join(results)
    
    def ask(self, prompt: str, stream: bool = True, max_iterations: int = 5) -> Generator[str, None, None]:
        """–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞–≥–µ–Ω—Ç—É —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        messages = self._build_messages(prompt)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self.history.append({
            'role': 'user',
            'content': prompt,
            'timestamp': datetime.now().isoformat()
        })
        
        iteration = 0
        full_response = ""
        
        while iteration < max_iterations:
            iteration += 1
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
            current_response = ""
            if self.provider == "ollama":
                generator = self._call_ollama(messages, stream=stream)
            elif self.provider == "lmstudio":
                generator = self._call_lmstudio(messages, stream=stream)
            elif self.provider == "local_transformers":
                generator = self._call_transformers(messages, stream=stream)
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.provider}")
            
            for chunk in generator:
                current_response += chunk
                if stream:
                    yield chunk
            
            full_response += current_response
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            if self.use_mcp and self.mcp_tools:
                tool_calls = self._parse_tool_calls(current_response)
                
                if tool_calls:
                    # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
                    tool_results = self._execute_tool_calls(tool_calls)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
                    messages.append({
                        'role': 'assistant',
                        'content': current_response
                    })
                    messages.append({
                        'role': 'user',
                        'content': f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤:\n{tool_results}\n\n–ü—Ä–æ–¥–æ–ª–∂–∏ –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."
                    })
                    
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                    continue
            
            # –ù–µ—Ç –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –æ–Ω–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã - –∑–∞–≤–µ—Ä—à–∞–µ–º
            break
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç
        self.history.append({
            'role': 'assistant',
            'content': full_response,
            'timestamp': datetime.now().isoformat()
        })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if self.config['agent'].get('save_history', True):
            self._save_history()
    
    def _save_history(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        history_file = self.history_path / f"history_{timestamp}.json"
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, ensure_ascii=False, indent=2)
    
    def clear_history(self):
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        self.history = []
        console.print("[green]–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞[/green]")
    
    def load_history(self, file_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        with open(file_path, 'r', encoding='utf-8') as f:
            self.history = json.load(f)
        console.print(f"[green]–ò—Å—Ç–æ—Ä–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {file_path}[/green]")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è CLI"""
    agent = CodeAgent()
    
    console.print("\n[bold cyan]ü§ñ AI Code Agent –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ![/bold cyan]")
    console.print("[dim]–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞, 'clear' –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏)[/dim]\n")
    
    while True:
        try:
            user_input = input("> ")
            
            if user_input.lower() in ['exit', 'quit', 'q']:
                console.print("[yellow]–î–æ —Å–≤–∏–¥–∞–Ω–∏—è![/yellow]")
                break
            
            if user_input.lower() == 'clear':
                agent.clear_history()
                continue
            
            if not user_input.strip():
                continue
            
            console.print("\n[cyan]–ê–≥–µ–Ω—Ç –¥—É–º–∞–µ—Ç...[/cyan]\n")
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç –ø–æ —á–∞—Å—Ç—è–º
            response = ""
            for chunk in agent.ask(user_input, stream=True):
                response += chunk
                print(chunk, end='', flush=True)
            
            print("\n")  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞
            
        except KeyboardInterrupt:
            console.print("\n[yellow]–ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º[/yellow]")
            break
        except Exception as e:
            console.print(f"[red]–û—à–∏–±–∫–∞: {e}[/red]")


if __name__ == "__main__":
    main()

