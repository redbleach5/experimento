# üì¶ –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ

## –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **–û–°**: Windows 10/11, Linux, macOS
- **GPU**: NVIDIA RTX 3090 (24GB VRAM) –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è
- **RAM**: 32GB (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- **Python**: 3.9 –∏–ª–∏ –≤—ã—à–µ
- **CUDA**: 11.8+ (–¥–ª—è GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è)
- **–°–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ**: ~10GB –¥–ª—è –º–æ–¥–µ–ª–µ–π –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

## –ü–æ—à–∞–≥–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python

#### Windows:
1. –°–∫–∞—á–∞–π—Ç–µ Python 3.9+ —Å https://www.python.org/downloads/
2. –ü—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –æ—Ç–º–µ—Ç—å—Ç–µ "Add Python to PATH"
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É:
   ```bash
   python --version
   ```

#### Linux:
```bash
sudo apt update
sudo apt install python3 python3-pip
```

#### macOS:
```bash
brew install python3
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA (–¥–ª—è GPU)

#### Windows:
1. –°–∫–∞—á–∞–π—Ç–µ CUDA Toolkit: https://developer.nvidia.com/cuda-downloads
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA 11.8 –∏–ª–∏ –≤—ã—à–µ
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É:
   ```bash
   nvidia-smi
   ```

#### Linux:
```bash
# –°–ª–µ–¥—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º NVIDIA –¥–ª—è –≤–∞—à–µ–≥–æ –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤–∞
# https://developer.nvidia.com/cuda-downloads
```

### 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama

#### Windows:
1. –°–∫–∞—á–∞–π—Ç–µ —É—Å—Ç–∞–Ω–æ–≤—â–∏–∫: https://ollama.ai/download/windows
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —É—Å—Ç–∞–Ω–æ–≤—â–∏–∫
3. Ollama –¥–æ–ª–∂–µ–Ω –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

#### Linux:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### macOS:
```bash
brew install ollama
```

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É:
```bash
ollama --version
```

–ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama (–µ—Å–ª–∏ –Ω–µ –∑–∞–ø—É—â–µ–Ω):
```bash
ollama serve
```

### 4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

–ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:

```bash
pip install -r requirements.txt
```

–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv venv

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Windows)
venv\Scripts\activate

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Linux/Mac)
source venv/bin/activate

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt
```

### 5. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

–î–ª—è RTX 3090 —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –º–æ–¥–µ–ª–∏:

#### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è (–ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å):
```bash
ollama pull deepseek-coder:6.7b
```

#### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:
```bash
# –ë–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ
ollama pull codellama:13b

# –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
ollama pull qwen2.5-coder:7b

# –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –∫–æ–¥–∞
ollama pull starcoder2:7b
```

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:
```bash
ollama list
```

### 6. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–û—Ç–∫—Ä–æ–π—Ç–µ `config.yaml` –∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ:

```yaml
model:
  model_name: "deepseek-coder:6.7b"  # –í–∞—à–∞ –º–æ–¥–µ–ª—å
```

### 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏:

```bash
python setup.py
```

–ò–ª–∏ –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ Python
python --version

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama
ollama list

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
python -c "import torch; print(torch.__version__)"
```

## –ó–∞–ø—É—Å–∫

### CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:
```bash
python cli.py
```

### –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:
```bash
python web_ui.py
```
–û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä: http://127.0.0.1:8000

### –ß–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç:
- Windows: `run.bat`
- Linux/Mac: `bash run.sh` –∏–ª–∏ `chmod +x run.sh && ./run.sh`

## –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### Ollama –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

**Windows:**
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω (–∏–∫–æ–Ω–∫–∞ –≤ —Ç—Ä–µ–µ)
- –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Ollama –∏–∑ –º–µ–Ω—é –ü—É—Å–∫

**Linux/Mac:**
```bash
ollama serve
```

### –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
ollama list

# –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å
ollama pull deepseek-coder:6.7b
```

### –û—à–∏–±–∫–∏ —Å CUDA

1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ CUDA —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞:
   ```bash
   nvidia-smi
   ```

2. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```

### –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å (6.7b –≤–º–µ—Å—Ç–æ 13b)
- –í–∫–ª—é—á–∏—Ç–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –≤ `config.yaml`:
  ```yaml
  gpu:
    use_8bit: true
  ```

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU:
   ```bash
   nvidia-smi
   ```

2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU (–≤ –ª–æ–≥–∞—Ö Ollama)

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è RTX 3090

–í `config.yaml`:

```yaml
gpu:
  use_gpu: true
  max_memory: 24
  use_flash_attention: true
  use_8bit: false  # –ù–µ –Ω—É–∂–Ω–æ –¥–ª—è 6.7b –º–æ–¥–µ–ª–µ–π
```

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `system_prompt` –≤ `config.yaml` –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞.

## –ì–æ—Ç–æ–≤–æ!

–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AI Code Agent –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏! üéâ

